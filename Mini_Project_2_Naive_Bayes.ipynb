{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mini Project 2_Naive Bayes",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "InLceHnL7gLU"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import sklearn\n",
        "from sklearn.feature_extraction import text\n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEIVDtubiJA1"
      },
      "source": [
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKX8xncZcoJv"
      },
      "source": [
        "### Bernoulli Na√Øve Bayes from Scratch\n",
        "class BernoulliNB():\n",
        "    def fit(self, X, y, k = 8):\n",
        "        n,m = X.shape\n",
        "\n",
        "        self.theta_k = np.zeros(k)\n",
        "        self.parameterMatrix = np.zeros(shape = (k,m))\n",
        "\n",
        "        for i in range(k):\n",
        "            i_class_data = X[(y==i).flatten(), :] \n",
        "            self.theta_k[i] = i_class_data.shape[0]/n\n",
        "            \n",
        "            # Laplace smoothing\n",
        "            ones = np.ones(shape = (1,m))\n",
        "            zeros = np.zeros(shape = (1,m))\n",
        "            i_class_data = np.vstack([i_class_data, ones, zeros]) \n",
        "\n",
        "            self.parameterMatrix[i] = np.mean(i_class_data,axis = 0)\n",
        "\n",
        "    def predict(self, X):\n",
        "        probability = (X @ np.log(self.parameterMatrix.T + 1e-5)) + ((1-X) @ (np.log((1 - self.parameterMatrix.T) + 1e-5))) + np.log(self.theta_k + 1e-5)\n",
        "        return np.argmax(probability, axis = 1) \n",
        "         \n",
        "BNB = BernoulliNB()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqAT3GnZ81J9"
      },
      "source": [
        "### K-fold Cross Validation\n",
        "def kfold_validation(model, X, y, numFolds=10):\n",
        "\n",
        "    kf = KFold(n_splits=numFolds,shuffle=True,random_state=0)\n",
        "    print(\"\\nIn this K-fold Cross Validation, K = \", kf.n_splits)\n",
        "    totalAccuracy = 0\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train,X_test = X[train_index], X[test_index]\n",
        "        y_train,y_test = y[train_index], y[test_index]\n",
        "\n",
        "        model.fit(X = X_train, y = y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        totalAccuracy += metrics.accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "\n",
        "    return totalAccuracy / numFolds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjYSHDWHOPEW"
      },
      "source": [
        "### Data Preprocessing\n",
        "def data_preprocess(train_file, test_data):\n",
        "    # load\n",
        "    data_train = np.array(pd.read_csv(train_file))\n",
        "    data_test = np.array(pd.read_csv(test_data))\n",
        "    X_train = data_train[:,0]\n",
        "    y_train_origin = data_train[:,1]\n",
        "    X_test = data_test[:,1]\n",
        "\n",
        "    # preprocessing\n",
        "\n",
        "    # label\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    le.fit(['rpg','anime','datascience','hardware','cars','gamernews','gamedev','computers'])\n",
        "    y_train = le.transform(y_train_origin)\n",
        "    class_num = len(np.unique(y_train))\n",
        "\n",
        "    # Vectorizer and Normalizer\n",
        "    vectorizer = text.TfidfVectorizer(max_features = 2000, binary = True, stop_words = text.ENGLISH_STOP_WORDS)\n",
        "    normalizer_train = preprocessing.Normalizer()\n",
        "    \n",
        "    vectors_train = vectorizer.fit_transform(X_train)\n",
        "    vectors_test = vectorizer.transform(X_test)\n",
        "    vectors_train = normalizer_train.transform(vectors_train).A\n",
        "    vectors_test = normalizer_train.transform(vectors_test).A\n",
        "\n",
        "    return vectors_train, y_train, vectors_test, class_num, le"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn1avYASQNuH"
      },
      "source": [
        "def main(model, train_file, test_data, numFolds = 10, class_num = 8):\n",
        "    start = time.time()\n",
        "\n",
        "    print(model)\n",
        "\n",
        "    # data preprocessing\n",
        "    X_train, y_train, X_test, class_num, le = data_preprocess(train_file, test_data)\n",
        "\n",
        "    # K-fold Cross Validation\n",
        "    \n",
        "    Average_accuracy = kfold_validation(model, X_train, y_train, numFolds)\n",
        "    print('\\nThe average accuracy of {}-fold cross validation is: {:.5f}'.format(numFolds, Average_accuracy))\n",
        "\n",
        "    # train with the whole training dataset\n",
        "    model.fit(X_train, y_train, class_num)\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    print('\\nPerformance metrics:\\n', metrics.classification_report(y_train, y_train_pred))\n",
        "\n",
        "    # predict with test dataset\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # final output\n",
        "    y_pred_inversed = le.inverse_transform(y_test_pred)\n",
        "    print('\\nPredicted labels of the test dataset:\\n', y_pred_inversed)\n",
        "    \n",
        "    # Run time\n",
        "    end = time.time()\n",
        "    run_time = end - start\n",
        "    print('\\nRun time: {:.2f}s\\n'.format(run_time))\n",
        "\n",
        "    return y_pred_inversed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYrWYDjTUS8b",
        "outputId": "1c340bbc-e9ad-4549-8a75-82efb21ca7ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Test_pred = main(BNB, 'train.csv', 'test.csv', 10, 8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<__main__.BernoulliNB object at 0x7feb55a8d9e8>\n",
            "\n",
            "In this K-fold Cross Validation, K =  10\n",
            "\n",
            "The average accuracy of 10-fold cross validation is: 0.79270\n",
            "\n",
            "Performance metrics:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.84      0.90      1304\n",
            "           1       0.82      0.97      0.89      2064\n",
            "           2       0.98      0.13      0.24       427\n",
            "           3       0.85      0.96      0.90      2382\n",
            "           4       0.97      0.47      0.64      1016\n",
            "           5       0.91      0.41      0.57       784\n",
            "           6       0.73      0.90      0.80      1617\n",
            "           7       0.79      0.95      0.86      1988\n",
            "\n",
            "    accuracy                           0.83     11582\n",
            "   macro avg       0.88      0.71      0.72     11582\n",
            "weighted avg       0.85      0.83      0.81     11582\n",
            "\n",
            "\n",
            "Predicted labels of the test dataset:\n",
            " ['datascience' 'anime' 'rpg' ... 'gamedev' 'cars' 'cars']\n",
            "\n",
            "Run time: 4.09s\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1zoaNumE-Mo"
      },
      "source": [
        "11# Save to CSV\n",
        "id = np.arange(len(Test_pred[0]))\n",
        "Test_pred = np.vstack([id, np.array(Test_pred)]).T\n",
        "save = pd.DataFrame(Test_pred) \n",
        "save.to_csv(\"Test_pred.csv\", header = ['id', 'subreddit'], index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB3UPQrhKW6m"
      },
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "from bs4 import BeautifulSoup\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        \n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
        "    return text\n",
        "\n",
        "\n",
        "\"\n",
        "\n",
        "data_train['body_cleaned']=data_train['body']\n",
        "data_train['body_cleaned'] = data_train['body_cleaned'].apply(clean_text)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}